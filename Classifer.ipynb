{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "Loading the Dataset obtained from online "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('labeled_data.csv',index_col=0)\n",
    "df=df.drop(columns=['count','hate_speech','offensive_language','neither'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet\n",
       "0      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data PreParation\n",
    "We have cleaned the tweets without any handles, removed Special characters and removed unwanted punctuations.\n",
    "We did stemming and stop word removal on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function uses regex to remove links and unwanted punctuations and special characters in the tweets\n",
    "def split_it(tweet):\n",
    "    x = re.sub(r'@[a-zA-Z@#_$%^&*0-9;:]*',r'', tweet)\n",
    "    x= re.sub(r'&[@#$%&()0-9]*',r'',x)\n",
    "    x= re.sub(r'\\sRT\\s|!',r'',x)\n",
    "    x = re.sub(r'https?\\S+',r'',x)\n",
    "    x = x.translate(str.maketrans(string.punctuation,' '*len(string.punctuation)))\n",
    "    tokens = x.split()\n",
    "    ps = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [ps.stem(token) for token in tokens if token not in stop_words] \n",
    "    return ' '.join([token for token in tokens if token not in stop_words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>As woman complain clean hous amp man alway tak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>boy dat cold tyga dwn bad cuffin dat hoe 1st p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dawg ever fuck bitch start cri confus shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>look like tranni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet\n",
       "0      2  As woman complain clean hous amp man alway tak...\n",
       "1      1  boy dat cold tyga dwn bad cuffin dat hoe 1st p...\n",
       "2      1         dawg ever fuck bitch start cri confus shit\n",
       "3      1                                   look like tranni\n",
       "4      1     shit hear might true might faker bitch told ya"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet']=df['tweet'].apply(split_it)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data for future reference\n",
    "df.to_csv('cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the Data\n",
    "Data Splitting to build binary classifier for each category such a way that for each category data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0=df[df['class']==0]\n",
    "df_1=df[df['class']==1]\n",
    "df_2=df[df['class']==2]\n",
    "\n",
    "#getting data from other classifier to balance 0th category\n",
    "df_0=df_0.append(df_1[:715])\n",
    "df_0=df_0.append(df_2[:715])\n",
    "\n",
    "#getting data from other classifier to balance 1st category\n",
    "df_1=df_1.append(df_0[:1430])\n",
    "df_1=df_1.append(df_2[:4600])\n",
    "\n",
    "#getting data from other classifier to balance 2nd category\n",
    "df_2=df_2.append(df_2[:2000])\n",
    "df_2=df_2.append(df_0[:1000])\n",
    "df_2=df_2.append(df_1[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting all the values to a binary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0['class']=df_0['class'].apply(lambda x: 1 if x==0 else 0)\n",
    "df_1['class']=df_1['class'].apply(lambda x: 1 if x==1 else 0)\n",
    "df_2['class']=df_2['class'].apply(lambda x: 1 if x==2 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Train_X0, Test_X0, Train_Y0, Test_Y0 = train_test_split(df_0['tweet'],df_0['class'],test_size=0.3)\n",
    "Train_X1, Test_X1, Train_Y1, Test_Y1 = train_test_split(df_1['tweet'],df_1['class'],test_size=0.3)\n",
    "Train_X2, Test_X2, Train_Y2, Test_Y2 = train_test_split(df_2['tweet'],df_2['class'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectoriser and building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector(df):\n",
    "    Tfidf_vect = TfidfVectorizer(max_features=500)\n",
    "    Tfidf_vect.fit(df['tweet'])\n",
    "    return Tfidf_vect\n",
    "\n",
    "def pass_the_value(Tfidf_vect,Train_X,Test_X,Train_Y,Test_Y):\n",
    "    Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "    Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
    "    SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto',probability=True)\n",
    "    SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "    predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "    print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "    return SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  83.68298368298368\n",
      "SVM Accuracy Score ->  90.78681909885677\n",
      "SVM Accuracy Score ->  93.56469002695418\n"
     ]
    }
   ],
   "source": [
    "Tfidf_vect_cat_0=vector(df_0)\n",
    "svm_cat_0=pass_the_value(Tfidf_vect,Train_X0, Test_X0, Train_Y0, Test_Y0)\n",
    "\n",
    "\n",
    "Tfidf_vect_cat_1=vector(df_1)\n",
    "svm_cat_1=pass_the_value(Tfidf_vect_cat_1,Train_X1, Test_X1, Train_Y1, Test_Y1)\n",
    "\n",
    "Tfidf_vect_cat_2=vector(df_2)\n",
    "svm_cat_2=pass_the_value(Tfidf_vect_cat_2,Train_X2, Test_X2, Train_Y2, Test_Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15053589, 0.84946411])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[\"i hate black people\"]\n",
    "Tfidf_vect_cat_0 = Tfidf_vect.transform(text)\n",
    "Tfidf_vect_cat_1 = Tfidf_vect.transform(text)\n",
    "Tfidf_vect_cat_2 = Tfidf_vect.transform(text)\n",
    "\n",
    "predictions_0 = svm_cat_0.predict_proba(Tfidf_vect_cat_0)[0]\n",
    "predictions_1 = svm_cat_1.predict_proba(Tfidf_vect_cat_1)[0]\n",
    "predictions_2 = svm_cat_2.predict_proba(Tfidf_vect_cat_2)[0]\n",
    "\n",
    "predictions_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62949235, 0.37050765])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08491395, 0.91508605])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if prediction_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
